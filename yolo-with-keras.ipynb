{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/yolo-with-keras?scriptVersionId=214301778\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade git+https://github.com/keras-team/keras-cv -q","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom tqdm.auto import tqdm\nimport xml.etree.ElementTree as ET\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nimport keras_cv\nfrom keras_cv import bounding_box\nfrom keras_cv import visualization","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SPLIT_RATIO = 0.2\nBATCH_SIZE = 4\nLEARNING_RATE = 0.001\nEPOCH = 5\nGLOBAL_CLIPNORM = 10.0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_ids = [\n    \"car\",\n    \"pedestrian\",\n    \"trafficLight\",\n    \"biker\",\n    \"truck\",\n]\nclass_mapping = dict(zip(range(len(class_ids)), class_ids))\n\n# Path to images and annotations\npath_images = \"/kaggle/input/dataset/data/images/\"\npath_annot = \"/kaggle/input/dataset/data/annotations/\"\n\n# Get all XML file paths in path_annot and sort them\nxml_files = sorted(\n    [\n        os.path.join(path_annot, file_name)\n        for file_name in os.listdir(path_annot)\n        if file_name.endswith(\".xml\")\n    ]\n)\n\n# Get all JPEG image file paths in path_images and sort them\njpg_files = sorted(\n    [\n        os.path.join(path_images, file_name)\n        for file_name in os.listdir(path_images)\n        if file_name.endswith(\".jpg\")\n    ]\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def parse_annotation(xml_file):\n    tree = ET.parse(xml_file)\n    root = tree.getroot()\n\n    image_name = root.find(\"filename\").text\n    image_path = os.path.join(path_images, image_name)\n\n    boxes = []\n    classes = []\n    for obj in root.iter(\"object\"):\n        cls = obj.find(\"name\").text\n        classes.append(cls)\n\n        bbox = obj.find(\"bndbox\")\n        xmin = float(bbox.find(\"xmin\").text)\n        ymin = float(bbox.find(\"ymin\").text)\n        xmax = float(bbox.find(\"xmax\").text)\n        ymax = float(bbox.find(\"ymax\").text)\n        boxes.append([xmin, ymin, xmax, ymax])\n\n    class_ids = [\n        list(class_mapping.keys())[list(class_mapping.values()).index(cls)]\n        for cls in classes\n    ]\n    return image_path, boxes, class_ids\n\n\nimage_paths = []\nbbox = []\nclasses = []\nfor xml_file in tqdm(xml_files):\n    image_path, boxes, class_ids = parse_annotation(xml_file)\n    image_paths.append(image_path)\n    bbox.append(boxes)\n    classes.append(class_ids)","metadata":{},"outputs":[],"execution_count":null}]}