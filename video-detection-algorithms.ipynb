{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6664020,"sourceType":"datasetVersion","datasetId":3845355}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/video-detection-algorithms?scriptVersionId=176509701\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-05T15:57:59.29785Z","iopub.execute_input":"2024-05-05T15:57:59.298382Z","iopub.status.idle":"2024-05-05T15:57:59.909462Z","shell.execute_reply.started":"2024-05-05T15:57:59.298339Z","shell.execute_reply":"2024-05-05T15:57:59.908078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preparing the data**","metadata":{}},{"cell_type":"code","source":"# installing required packages\n!pip install git+https://github.com/sajjjadayobi/FaceLib.git\n!git clone https://github.com/Pongpisit-Thanasutives/Variations-of-SFANet-for-Crowd-Counting","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:57:59.911984Z","iopub.execute_input":"2024-05-05T15:57:59.912978Z","iopub.status.idle":"2024-05-05T15:58:20.554251Z","shell.execute_reply.started":"2024-05-05T15:57:59.912884Z","shell.execute_reply":"2024-05-05T15:58:20.552696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import required libraries\nimport cv2\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport glob\nimport torch\nfrom torchvision import transforms\n\n#import model\nimport os\nos.chdir('/kaggle/working/Variations-of-SFANet-for-Crowd-Counting')\nfrom models import M_SFANet_UCF_QNRF\n\n# import facelib\nfrom facelib import FaceDetector, AgeGenderEstimator","metadata":{"execution":{"iopub.status.busy":"2024-05-05T15:58:20.556578Z","iopub.execute_input":"2024-05-05T15:58:20.557028Z","iopub.status.idle":"2024-05-05T15:58:28.684394Z","shell.execute_reply.started":"2024-05-05T15:58:20.556986Z","shell.execute_reply":"2024-05-05T15:58:28.683411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the video to a series of images\ndef video_to_image (path, folder):\n    global exp_fld\n    \n    # importing video\n    vidcap = cv2.VideoCapture (path)\n    exp_fld = folder\n    \n    # error handling\n    try:\n        if not os.path.exists (exp_fld):\n            os.makedirs (exp_fld)\n    except OSError:\n        print ('Error: Creating directory of data')\n    Count = 0\n    sec = 0\n    frameRate = 1 # secs of the video\n    \n    while (True):\n        vidcap.set (cv2.CAP_PROP_POS_MSEC, sec * 1000)\n        hasFrames, image = vidcap.read ()\n        sec = sec + frameRate\n        sec = round (sec, 2)\n        \n        # exporting the image\n        if hasFrames:\n            name = './' + exp_fld + '/frame' + str (Count) + '.jpg'\n            cv2.imwrite (name, image)\n            Count += 1\n        else:\n            break\n    return print ('Image Exported')\n\n# setting the path\npath = ('/kaggle/input/aggressive-behavior-video-classification/files/aggressive')\n\n# extracting images and storing for a first video\nvideo_to_image ('/kaggle/input/aggressive-behavior-video-classification/files/aggressive/0.mp4', 'crowd')\n\n# extracting images for forth video\nvideo_to_image ('/kaggle/input/aggressive-behavior-video-classification/files/aggressive/3.mp4', 'movement')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:37:29.269843Z","iopub.execute_input":"2024-05-05T16:37:29.271706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# resizing the image\ndef img_re_sizing (dnst_mp, image):\n    # normalizing\n    dnst_mp = 255 * dnst_mp / np.max (dnst_mp)\n    dnst_mp = dnst_mp [0][0]\n    image = image [0]\n    \n    # empty image\n    result_img = np.zeros ((dnst_mp.shape [0] * 2, dnst_mp.shape [1] * 2))\n    \n    # iterate for each image\n    for i in range (result_img.shape [0]):\n        for j in range (result_img.shape [1]):\n            result_img [i][j] = dnst_mp [int (i / 2)]\n            [int (j / 2)] /3\n    result_img = result_img.astype (np.uint8, copy = False)\n    \n    # output\n    return result_img","metadata":{"execution":{"iopub.status.busy":"2024-05-05T16:36:26.200262Z","iopub.status.idle":"2024-05-05T16:36:26.200743Z","shell.execute_reply.started":"2024-05-05T16:36:26.200523Z","shell.execute_reply":"2024-05-05T16:36:26.200544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to get a heatmap\ndef generate_dstys_map (o, dsty, cc, image_location):\n    # define the fgr_imure\n    fgr_im = plt.fgr_imure ()\n    \n    # define size\n    col = 2\n    rws = 1\n    X = o\n    \n    # sum \n    add = int (np.sum (dsty))\n    \n    dsty = image_re_sizing (dsty, o)\n    \n    # adding original image and new generated heatmap image\n    for i in range (1, col * rws + 1):\n        # generate original image\n        if i == 1:\n            image = X\n            fgr_im.add_subplot (rws, col, i)\n            # setting axis\n            plt.gca().set_axis_off ()\n            plt.margins (0, 0)\n            \n            #locator\n            plt.gca().xaxis.set_major_locator (plt.NullLocator ())\n            plt.gca().yaxis.set_major_locator (plt.NullLocator ())\n            # adjusting subplots\n            plt.subplots_adjust (top = 1, bottom = 0, right = 1, left = 0,\n                                hspace = 0, wspace = 0)\n            # show image\n            plt.imshow (image)\n    # generate dstys image\n    if i == 2:\n        image = dsty\n        fgr_im.add_subplot (rws, col, i)\n        # setting axis\n        plt.gca().set_axis_off ()\n        plt.margins (0, 0)\n        # locator\n        plt.gca().xaxis.set_major_locator (plt.NullLocator ())\n        plt.gca().yaxis.set_major_locator (plt.NullLocator ())\n        # adjusting subplots\n        plt.subplots_adjust (top = 1, bottom = 0, right = 1, left = 0,\n                            hspace = 0, wspace = 0)\n        # adding count\n        plt.text (1, 80, 'M-SegNet * Est: '+ str (add)+',\n                 Gt: '+str (cc), fontsize = 7, weight = \"bold', color = 'w')\n        # show image \n        plt.imshow (image), cmap = CM.jet\n        \n# image_nm with location\nimage_nm = image_location.split ('/')[-1]\nimage_nm = image_nm.replace ('.jpg', '_heatmap.png')\n\n# saving the image\nplt.savefgr_im (image_location.split (image_nm)\n                [0]+'seg_'+ image_nm, transparent = True\n                bbox_inches = 'tight', pad_inches = 0.0, dpi = 200)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  getting count of peoples\ndef get_count_people (image):\n    # simple preprocessing\n    trans  = transforms.Compose ([transforms,ToTensor (),\n                                 transforms.Normalize ([0.485, 0.456, 0.406],\n                                                      [0.229, 0.224, 0.225])])\n    # sample image with height and width\n    img = Image.open (image).convert ('RGB')\n    height, width = img.size [1], img.size [0]\n    height = round (height / 16) * 16\n    width = round (width / 16) * 16\n    \n    # resize the image\n    img_den = cv2.resize (np.array (img), (width, height), cv2.INTER_CUBIC)\n    \n    # transform \n    img = trans (Image.fromarray (img_den))[None, :]\n    \n    # lets define the model\n    model = M_SFANet_UCF_QNRF.Model ()\n    \n    # load the model\n    model.load_state_dict (torch.load ('/content/best_M-SFANet_UCF_QNRF.pth',\n                                      map_location = torch.device ('cpu')))\n    \n    # evaluating the model\n    model.eval ()\n    dnst_mp = model (img)\n    \n    # final count \n    count = torch.sum (dnst_mp).item ()\n    \n    # return count, density and map\n    return count, img_den, dnst_mp","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing the images\nimage_location = []\npath_sets = ['/content/crowd']\n\n# loading all the images\nfor path in path_sets:\n    for img_path in glob.glob (os.path.join (path, '*.jpg')):\n        image_location.append (img_path)\nimage_location [:3]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting the count of people by image\n# define empty list\nlist_df = []\n\n# loop through each image\nfor i in image_location:\n    count, img_den, dnst_mp = get_count_people (i)\n    generate_dens_map (img_den, dnst_mp.cpu().detach ().numpy(), 0, i)\n    list_df = list_df + [[i, count]]\n    \n# create the dataframe with image id and count\ndf = pd.DataFrame (list_df, columns = ['image', 'count'])\n\n# sort and show\ndf.sort_values (['image']).head ()\n\ndf.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.histplot (data = df['count'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting all the images from the path\nimage_location = []\npath_sets = ['content/movement']\n\n# loading all images\nfor path in path_sets:\n    for img_path in glob.glob (os.path.join (path, '*.jpg')):\n        image_location.append (img_path)\n\nimage_location [:3]\n\n# getting the count of people by image\nlist_df = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking if there is any movement for each frame in video\nfor i in image_location:\n    count, img_den, dnst_mp = get_count_people (i)\n    generate_dens_map (img_den, dnst_mp.cpu().detach().numpy(), o, i)\n    list_df = list_df + [[i, count]]\n    \n# detecting the data into dataframe\ndetected_df = pd.DataFrame (list_df, columns = ['image', 'count'])\ndetected_df ['movement'] = np.where (detected_df ['count'] > 3, 'yes', 'no')\ndetected_df.filter (items = [45, 56, 53], axis = 0)","metadata":{},"execution_count":null,"outputs":[]}]}